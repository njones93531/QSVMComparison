{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3c66978-f764-46be-8429-cfdd4afc7d24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from qiskit import transpile\n",
    "from qiskit_aer import Aer\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit.circuit import (\n",
    "    Parameter, QuantumCircuit, ClassicalRegister, QuantumRegister\n",
    ")\n",
    "from qiskit.primitives import StatevectorSampler\n",
    "from qiskit_algorithms.state_fidelities import ComputeUncompute\n",
    "from qiskit_algorithms.optimizers import COBYLA, SPSA, SLSQP\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel, FidelityStatevectorKernel\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "from qiskit.circuit.library import ZFeatureMap, ZZFeatureMap\n",
    "from qiskit.visualization import plot_histogram\n",
    "from qiskit.primitives import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "917297a6-282f-430b-8ad6-5e6ee3012bb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and preprocessing the dataset...\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Fetch and preprocess the dataset\n",
    "print(\"Fetching and preprocessing the dataset...\")\n",
    "data = fetch_covtype(shuffle=True, as_frame=True)\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4f78d7c-e9ca-4318-a52a-b57d0deb7245",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalize features to [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9de3a71-2c17-4b2c-9d2d-215155dbb725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d2c53469-eabb-46bc-96b8-04bb7c93b412",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class BaggingQSVM(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_model=QSVC(), n_estimators=10, classes_=None, n_features_in_=None, is_fitted_=True, models=[], n_components=2, random_state=None, n_jobs=-1):\n",
    "        self.base_model = base_model  # Base classifier (Quantum SVM)\n",
    "        self.n_estimators = n_estimators  # Number of models (Quantum SVM classifiers)\n",
    "        self.n_components = n_components  # Number of PCA components\n",
    "        self.random_state = random_state  # Random seed for reproducibility\n",
    "        self.n_jobs = n_jobs  # Number of jobs to run in parallel\n",
    "        self.models = models # List to store trained models\n",
    "        \n",
    "        # Explicit attributes for scikit-learn compatibility\n",
    "        self.classes_ = classes_  # Unique class labels\n",
    "        self.n_features_in_ = n_features_in_  # Number of features in training data\n",
    "        self.is_fitted_ = is_fitted_  # Flag to indicate if the model is fitted\n",
    "\n",
    "\n",
    "    def _train_model(self, X_chunk, y_chunk):\n",
    "        \"\"\"Train a single SVM model on a chunk of data\"\"\"\n",
    "        if len(np.unique(y_chunk)) == 1:\n",
    "            print(\"Skipping chunk due to single class in the chunk.\")\n",
    "            return None\n",
    "        \n",
    "        # Apply PCA to reduce the number of features\n",
    "        X_chunk_pca = PCA(n_components=self.n_components).fit_transform(X_chunk)\n",
    "\n",
    "        # Define the quantum feature map and quantum kernel\n",
    "        feature_map = ZZFeatureMap(feature_dimension=X_chunk_pca.shape[1], reps=2)\n",
    "        qkernel = FidelityQuantumKernel(feature_map=feature_map)\n",
    "\n",
    "        # Instantiate the QSVM model with the quantum kernel\n",
    "        model = self.base_model.set_params(quantum_kernel=qkernel)\n",
    "\n",
    "        # Train the QSVM model on this chunk\n",
    "        model.fit(X_chunk_pca, y_chunk)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        np.random.seed(self.random_state)\n",
    "\n",
    "        # Split the data into disjoint chunks\n",
    "        chunk_size = X.shape[0] // self.n_estimators\n",
    "        chunks = [(X[i*chunk_size:(i+1)*chunk_size], y[i*chunk_size:(i+1)*chunk_size]) for i in range(self.n_estimators)]\n",
    "\n",
    "        # Parallelize the training of n_estimators models\n",
    "        models = Parallel(n_jobs=self.n_jobs)(delayed(self._train_model)(X_chunk, y_chunk) for X_chunk, y_chunk in chunks)\n",
    "\n",
    "        # Store the trained models\n",
    "        self.models = models\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not self.is_fitted_:\n",
    "            raise ValueError(\"This BaggingQSVM instance is not fitted yet.\")\n",
    "        # Collect predictions from all models\n",
    "        predictions = np.zeros((self.n_estimators, X.shape[0]))\n",
    "\n",
    "        # Apply PCA to the input data before prediction\n",
    "        X_pca = PCA(n_components=self.n_components).fit_transform(X)\n",
    "\n",
    "        for i, model in enumerate(self.models):\n",
    "            predictions[i, :] = model.predict(X_pca)\n",
    "\n",
    "        # Majority voting for classification\n",
    "        return np.apply_along_axis(lambda x: np.bincount(x.astype(int)).argmax(), axis=0, arr=predictions)\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        if not self.is_fitted_:\n",
    "            raise ValueError(\"This BaggingQSVM instance is not fitted yet.\")\n",
    "        \n",
    "        X_pca = PCA(n_components=self.n_components).fit_transform(X)\n",
    "        decision_scores = np.zeros((len(self.models), X.shape[0]))\n",
    "        for i, model in enumerate(self.models):\n",
    "            decision_scores[i, :] = model.decision_function(X_pca)\n",
    "        return np.mean(decision_scores, axis=0)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if not self.is_fitted_:\n",
    "            raise ValueError(\"This BaggingQSVM instance is not fitted yet.\")\n",
    "        # Collect probabilities from all models\n",
    "        probas = np.zeros((self.n_estimators, X.shape[0], 2))  # Two classes (+1 and -1)\n",
    "\n",
    "        # Apply PCA to the input data before prediction\n",
    "        X_pca = PCA(n_components=self.n_components).fit_transform(X)\n",
    "\n",
    "        for i, model in enumerate(self.models):\n",
    "            probas[i, :, :] = model.predict_proba(X_pca)\n",
    "\n",
    "        # Average the probabilities\n",
    "        return np.mean(probas, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "526ee88d-62a8-4a6a-85b6-cb5bfe053618",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training QSVM models in One-vs-All configuration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks      | elapsed:   37.2s\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks      | elapsed:  2.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=1)]: Done   7 tasks      | elapsed:  4.2min\n"
     ]
    }
   ],
   "source": [
    "print(\"Training QSVM models in One-vs-All configuration...\")\n",
    "n_estimators = 10\n",
    "svm_clf = OneVsRestClassifier(BaggingQSVM(n_estimators=n_estimators, n_components=5, random_state=42, n_jobs=-1), verbose=10)\n",
    "svm_clf.fit(X_train[:1000], y_train[:1000])\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89c4e7e-a9ea-4a16-b65e-97f29745ff4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions in parallel on 1 cores...\n"
     ]
    }
   ],
   "source": [
    "n_jobs = 1\n",
    "# Function to predict on a chunk of data\n",
    "def predict_chunk(chunk):\n",
    "    return svm_clf.predict(chunk)\n",
    "\n",
    "# Split the test data into chunks\n",
    "n_chunks = n_jobs  # Adjust based on available memory and CPU cores\n",
    "X_test_chunks = np.array_split(X_test[:50], n_chunks)\n",
    "\n",
    "print(f\"Making predictions in parallel on {n_jobs} cores...\")\n",
    "y_pred_chunks = Parallel(n_jobs=1)(delayed(predict_chunk)(chunk) for chunk in X_test_chunks)\n",
    "\n",
    "# Combine results\n",
    "y_pred = np.concatenate(y_pred_chunks)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b035571-f518-449a-90d7-72561bcfdb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the classifier\n",
    "print(\"Evaluating the model...\")\n",
    "accuracy = accuracy_score(y_test[:50], y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test[:50], y_pred))\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a806b067-933f-495f-b891-80a17b3abdc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QiskitEnv",
   "language": "python",
   "name": "qiskitenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
